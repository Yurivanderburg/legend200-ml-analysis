In this work, a Transformer-based approach to pulse shape discrimination was developed for the LEGEND-200 experiment, aiming to improve the separation of signal-like events from background noise in the search for neutrinoless double beta decay.
The model developed achieved a PSD efficiency of $(86.7 \pm 1.3)$\% at $Q_{\beta \beta}$, which agrees with the conventional A/E method $(84.3 \pm 0.5)$\%. A two-sided test of the difference between Transformer-based PSD efficiency and A/E yields $p = 0.08$, indicating that the observed 2.4\% difference is not statistically significant at the 5\% level.
While the Transformer-based method demonstrates a higher central efficiency, it also exhibits a larger uncertainty. This broader uncertainty reflects not just statistical variation, but also contributions from model variance and possible sensitivity to detector-specific features. In contrast to the A/E method, which is calibrated per detector and period, the Transformer is trained globally across all detectors and periods. This choice enables cross-detector generalization but can also introduce performance fluctuations when the training data does not sufficiently capture detector-to-detector variation. The elevated uncertainty may therefore indicate a trade-off between generalization and robustness, and suggests the need for better-balanced training data. 

A Bayesian $0 \nu \beta \beta$ decay sensitivity analysis yields signal half-rate limits of $\mathcal{S} = 8.23^{+3.65}_{-1.76} \times 10^{-28}$ (A/E) and $\mathcal{S} < 8.00^{+3.42}_{-1.71} \times 10^{-28} \; \mathrm{yr}^{-1}$ (Transformer), if we assume the LEGEND-200 design goals are reached (background index $2 \times 10^{-4}$ counts/(keV$\cdot$kg$\cdot$yr), exposure $1000 \;\mathrm{kg \cdot yr}$). Both Transformer-based method ($T^{0 \nu}_{1/2} = 1.25^{+0.34}_{-0.37} \times 10^{27}$yr) and conventional A/E ($T^{0 \nu}_{1/2} = 1.22^{+0.33}_{-0.37} \times 10^{27}$yr) cuts agree within uncertainty, validating the Transformer-based approach as a viable alternative for pulse shape discrimination. 

Although a significant sensitivity improvement was not yet achieved, these results demonstrate that machine-learning techniques, particularly Transformer architectures, can achieve performance comparable to well-established PSD methods refined and optimized extensively over many years.
However, the Transformer introduces additional computational overhead, since training requires labeled datasets generated using conventional methods. This cost is largely a one-time expense, as the training would be repeated or updated only when detector conditions change. Once trained, classification of new waveforms is relatively fast, so the computational cost is amortized over large amounts of data. 
With further development, the Transformer-based PSD method shows promise for enhancing sensitivity in rare-event searches, though several aspects still require improvement.

First, the quality and consistency of training data should be improved by applying stricter data cleaning procedures, more rigorous detector selection, and better data balance (across energies and detectors) to increase the model's robustness and reduce sensitivity to unwanted features. 

Second, further investigation is needed into the $^{56}$Co waveforms, as their inclusion in the training set led to poor generalization of events below 1.5~MeV, resulting in reduced PSD performance in the $2 \nu \beta \beta$ decay energy region. This again highlights the need for improved training data, particularly in terms of data quality and data balance. 

Third, incorporating pulse shape simulations and domain adaptation techniques could help mitigate detector-specific effects and improve the model performance across a larger energy region.  

If Transformer-based (or other ML-based) PSD methods continue to demonstrate competitive performance, future work should also address their integration into the experiment's digital signal processing pipeline. 
As LEGEND progresses towards its ton-scale goals, deep learning-based PSD methods may become a critical component in maximizing the experiment's sensitivity to rare physics beyond the Standard Model. 
Their scalability could not only enhance event classification but also enable advanced techniques such as unsupervised anomaly detection, offering new avenues for discovery. 